environment:
  name: Quadcopter-v0
  num_envs: 2
  environment_kwargs:
    normalized_actions: true
    normalized_observations: true
    fixed_start: false

algorithm:
  name: PPO
  total_timesteps: 15000000
  save_every_timestep: 10000000
  algorithm_kwargs:
    gamma: 0.9990588957223104
    gae_lambda: 0.9947176601223783
    vf_coef: 0.5
    max_grad_norm: 0.5
    learning_rate: 0.001177786412072332
    learning_rate_schedule:
      type: lin

    n_steps: 232
    n_epochs: 2
    batch_size: 464
    clip_range: 0.2

policy:
  save_prefix: model
  policy_kwargs:
    net_arch:
      pi: [256, 256]
      vf: [256, 256]
    activation_fn: relu
    optimizer_class: rmsprop
    log_std_init: -0.40098797058762214
    ortho_init: true
