environment:
  name: GPUQuadcopterTT
  eval_envname: QuadcopterTT
  num_envs: 602
  normalized_rewards: false
  environment_kwargs:
    trajectory_file: 'trajectory_sine.mat'
    param:
      T: 3.
      dt: 0.004
      max_thrust_factor: 2
    reference_trajectory_horizon: 1.
    normalized_actions: true
    normalized_observations: true
    alpha_cost: 5.693
    alpha_action_cost: 5.693
    alpha_terminal_cost: 0.3166

algorithm:
  name: PPO
  total_timesteps: 60000000
  save_every_timestep: 60000000
  algorithm_kwargs:
    gamma: 0.9984539792726858
    gae_lambda: 0.99
    ent_coef: 0.0009916153167506478
    vf_coef: 0.5
    normalize_advantage: false
    max_grad_norm: 0.9216909281395821
    learning_rate: 1.7723023590427873e-05
    learning_rate_schedule:
      type: kla
      target_kl: 0.005
    n_steps: 132
    n_epochs: 15
    batch_size: 3973
    clip_range: 0.2

policy:
  save_prefix: model
  policy_kwargs:
    net_arch:
      pi: [256, 256, 256]
      vf: [256, 256, 256]
    activation_fn: relu
    optimizer_class: rmsprop
    log_std_init: -0.034578540624727594
    ortho_init: true
