environment:
  name: Unicycle-v0
  num_envs: 5
  environment_kwargs:
    normalized_actions: true
    fixed_start: false
    expand_limits: false

algorithm:
  name: PPO
  total_timesteps: 15000000
  algorithm_kwargs:
    gamma: 0.9995
    gae_lambda: 0.9507904674110622
    vf_coef: 0.5
    max_grad_norm: 0.5
    learning_rate: 0.0003253012923481764
    learning_rate_schedule:
      type:
    n_steps: 480
    n_epochs: 1
    batch_size: 2400
    clip_range: 0.2

policy:
  save_prefix: model
  policy_kwargs:
    net_arch:
      pi: [128, 128]
      vf: [128, 128]
    activation_fn: relu
    optimizer_class: rmsprop
    log_std_init: -2.3
    ortho_init: true
