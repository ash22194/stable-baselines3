environment:
  name: 'GPUUnicycle'
  eval_envname: 'Unicycle-v0'
  num_envs: 1
  normalized_rewards: False
  environment_kwargs:
    nonlinear_cost: False
    normalized_actions: True
    normalized_observations: True
    dt: 0.003
    T: 3.
    alpha_cost: 0.79
    alpha_action_cost: 0.79
    alpha_terminal_cost: 0.1

algorithm:
  name: 'PPO'
  total_timesteps: 30000000
  save_every_timestep: 25000000
  algorithm_kwargs:
    gamma: 0.99
    gae_lambda: 0.95
    ent_coef: 0.
    vf_coef: 0.5
    max_grad_norm: 0.5
    learning_rate: 0.0004
    learning_rate_schedule: 
      type: 'lin'
    n_steps: 320
    n_epochs: 5
    batch_size: 0.25
    clip_range: 0.2
    device: 'cuda'

policy:
  save_prefix: 'model'
  policy_kwargs:
    net_arch:
      pi: [256, 256, 256]
      vf: [256, 256, 256]
    activation_fn: 'relu'
    optimizer_class: 'rmsprop'
    log_std_init: -2.3
    ortho_init: True